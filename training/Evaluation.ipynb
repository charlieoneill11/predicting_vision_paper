{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83631c7d-b505-4ce2-9b75-b8543b1dfbdf",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f8e116-16c3-422e-8203-69698b95f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta \n",
    "import numpy as np\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991ffb-22d8-468c-a924-7e69a3b16ab6",
   "metadata": {},
   "source": [
    "## Entire main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63db9673-b794-4436-8017-39292f8e3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta \n",
    "import numpy as np\n",
    "import config\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93475fbf-7c29-4a9c-a917-b7f9090c7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_cutoff(df, cutoff_year, cutoff_visits):\n",
    "    # patients must have this many years of data to be included.\n",
    "    frames = []\n",
    "    id_list = df.eye_id.unique()\n",
    "    for eye in id_list:\n",
    "        pdf = df[df.eye_id == eye]\n",
    "        dates = (pd.to_datetime(pdf.admission_date)).to_list()\n",
    "        if ((dates[-1] - dates[0]).days)/365 >= cutoff_year and len(pdf)>=cutoff_visits: \n",
    "            frames.append(pdf)\n",
    "    return pd.concat(frames)\n",
    "\n",
    "def cut_time(df, cutoff_time):\n",
    "        # shortens a patient's dataframe to x years after initiation.\n",
    "        frames = []\n",
    "        id_list = df.eye_id.unique()\n",
    "        for eye in id_list:\n",
    "            pdf = df[df.eye_id == eye]\n",
    "            pdf.admission_date = pd.to_datetime(pdf.admission_date)\n",
    "            dates = pdf['admission_date'].to_list()\n",
    "            first = pd.to_datetime(dates[0])\n",
    "            cutoff = first + timedelta(days=cutoff_time*365)\n",
    "            pdf = pdf[pdf['admission_date'] <= cutoff]\n",
    "            if len(pdf) > 0: frames.append(pdf)\n",
    "        return pd.concat(frames)\n",
    "    \n",
    "def impute_pdf(df):\n",
    "    fill_NaN = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imputed_df = pd.DataFrame(fill_NaN.fit_transform(df))\n",
    "    imputed_df.columns = df.columns\n",
    "    imputed_df.index = df.index\n",
    "    imputed_df.fillna(0, inplace=True)\n",
    "    return imputed_df\n",
    "\n",
    "def column_names(i):\n",
    "    return [f'va_{i}', f'int_{i}']\n",
    "\n",
    "def column_builder(i):\n",
    "    lst = []\n",
    "    for visits in range(1, i+1):\n",
    "        lst.extend(column_names(visits))\n",
    "    lst.append('mean_vision'), lst.append('std_vision')\n",
    "    lst.append('target_va')\n",
    "    lst.remove('int_1')\n",
    "    return lst\n",
    "\n",
    "def reshape_pdf(pdf, n_visits):\n",
    "    nums, columns = [], column_builder(n_visits)\n",
    "    pdf.fillna(0, inplace=True)\n",
    "    for i in range(n_visits): \n",
    "        nums.append(pdf.visual_acuity.iloc[i])\n",
    "        if i != 0: nums.append((pdf.admission_date.iloc[i] - pdf.admission_date.iloc[i-1]).days)\n",
    "    if n_visits > 6: nums.append(np.mean(pdf.visual_acuity))\n",
    "    else: nums.append(np.mean(pdf.visual_acuity.iloc[:n_visits+1]))\n",
    "    if n_visits > 3: nums.append(np.std(pdf.visual_acuity))\n",
    "    else: nums.append(np.std(pdf.visual_acuity.iloc[:n_visits+1]))\n",
    "    nums.append(pdf.visual_acuity.iloc[-1])\n",
    "    return pd.DataFrame(data=[nums], columns=columns)\n",
    "\n",
    "def encode_gender(g):\n",
    "    return 0 if g == \"Male\" else 1\n",
    "\n",
    "def reshape_df(df, n_visits):\n",
    "    eyes = df.eye_id.unique()\n",
    "    frames = []\n",
    "    for eye in eyes:\n",
    "        pdf = df[df.eye_id == eye]\n",
    "        try: frames.append(reshape_pdf(pdf, n_visits))\n",
    "        except: pass\n",
    "    return pd.concat(frames)\n",
    "\n",
    "def save_df_patients(n_years, n_visits=4):\n",
    "    df = pd.read_csv(\"~/Documents/github/paper/input/raw_test_data_cleaned.csv\")\n",
    "    df.drop(columns=['actual_drug_today', 'next_interval_in_weeks', 'InjNext',\n",
    "                     'laterality'], inplace=True)\n",
    "    df[\"irf\"] = 0\n",
    "    df[\"srf\"] = 0\n",
    "    df = patient_cutoff(df, n_years, 4)\n",
    "    df = cut_time(df, n_years)\n",
    "    df = reshape_df(df, n_visits)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c8e438-5b9e-4ad3-b67c-af8614ed6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(n_years):\n",
    "    test_df = save_df_patients(n_years)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_df = pd.read_csv(config.TRAINING_FILE[n_years-1])\n",
    "    features = ['va_1', 'va_2', 'int_2', 'va_3', 'int_3', 'va_4', 'int_4', \n",
    "                'mean_vision', 'std_vision', 'target_va']\n",
    "    train_df = train_df[features]\n",
    "    return train_df, test_df\n",
    "\n",
    "tabnet_params = {\"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"verbose\":0,\n",
    "                 \"optimizer_params\":dict(lr=2e-2),\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\"\n",
    "                }\n",
    "\n",
    "def score(model, X, y, cv=5, scoring='neg_mean_squared_error'):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def run(df, clf, rf=False):\n",
    "    # create inputs and targets\n",
    "    X, y = df.drop(columns=['target_va']).values, df.target_va.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "    # score the model\n",
    "    if rf: clf.fit(X_train, y_train)\n",
    "    else: kfold_tabnet(clf, X, y.reshape(-1, 1))\n",
    "\n",
    "def kfold_tabnet(clf, X, y):\n",
    "    rmses = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        rmse = fit_tabnet(clf, X_train, y_train, X_test, y_test)\n",
    "        rmses.append(rmse)\n",
    "    final_rmse, rmse_std = np.round(np.mean(rmses), 2), np.round(np.std(rmses), 2)\n",
    "    print(f\"Train-set RMSE: mean={final_rmse}, std={rmse_std}\")\n",
    "    \n",
    "def fit_tabnet(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)],\n",
    "            eval_metric=['rmse'], patience=1000, max_epochs=10000)\n",
    "    preds = clf.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return rmse\n",
    "\n",
    "def evaluate(test_df, clf):\n",
    "    # create inputs and targets\n",
    "    X, y = test_df.drop(columns=['target_va']).values, test_df.target_va.values\n",
    "    # find rmse \n",
    "    preds = clf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    print(f\"The RMSE on the test-set was {rmse} logMAR letters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6ce3f1-aba5-458f-8214-45af52cbc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_years, rf=False):\n",
    "    train_df, test_df = get_train_test(n_years)\n",
    "    if rf:\n",
    "        clf = ensemble.RandomForestRegressor()\n",
    "    else:\n",
    "        clf = TabNetRegressor(**tabnet_params)\n",
    "    run(train_df, clf, rf)\n",
    "    evaluate(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "681a6e1d-43c2-4a85-901a-8594bf564454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test-set was 15.321285476724013 logMAR letters.\n"
     ]
    }
   ],
   "source": [
    "main(3, rf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cddb96b-7181-49b4-afc1-f280060ce9f4",
   "metadata": {},
   "source": [
    "## Vanilla NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5601db95-cb52-4eee-a62e-052ec3b03c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years=3\n",
    "train_df = pd.read_csv(config.TRAINING_FILE[n_years-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "127faff7-770e-4e2a-8ee1-e05b893bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_df.drop(columns=['target_va']).values, train_df.target_va.values\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14524842-12dc-43ef-8188-d0f204b1ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = [], []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append([X_train[i], \n",
    "                       y_train[i]])\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append([X_test[i], \n",
    "                       y_test[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac81d5ff-1dd5-46c1-86d6-40372428ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=False, \n",
    "                                          batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False,\n",
    "                                          batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39a9b1a5-9980-4eda-9178-16cecc06ed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 17])\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "i1, l1 = next(iter(train_loader))\n",
    "print(i1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ff08a7c-a0cc-4d46-966d-5ef5550e9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.double()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = x.view(x.size(0), -1)      \n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "190ffbfe-2b0a-482c-8d93-cbb2475c76b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3821]], dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model works on a random row\n",
    "model = SimpleNet()\n",
    "test_row, test_label = X_train[0], y_train[0]\n",
    "model(test_row.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eca4ab01-7356-499e-bb4d-547d49ab2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def training_loop(model, optimiser, loss_fn, n_epochs, train_loader):\n",
    "    model.train()\n",
    "    for n in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for i, (eyes, labels) in enumerate(train_loader):\n",
    "            b_x = Variable(eyes)\n",
    "            b_y = Variable(labels)\n",
    "            output = model(b_x)\n",
    "            loss = loss_fn(output, b_y)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            loss_train += loss.item()\n",
    "            preds = model(eyes).detach().numpy()\n",
    "            rmse_train = np.sqrt(mean_squared_error(preds, labels))\n",
    "            \n",
    "        # validation metrics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for eyes, labels in test_loader:\n",
    "                preds = model(eyes)\n",
    "                rmse = np.sqrt(mean_squared_error(preds, labels))\n",
    "            \n",
    "        if n == 1 or n % 1000 == 0:\n",
    "            print(f'Epoch [{n}/{n_epochs}], Train Loss: {np.round(loss.item(), 2)}, Train RMSE: {np.round(rmse_train, 2)}, Validation RMSE = {rmse}')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b48ea47-dd47-48f0-9e5c-98910274557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Train Loss: 4710.6, Train RMSE: 68.04, Validation RMSE = 67.30324348370155\n",
      "Epoch [1000/10000], Train Loss: 386.93, Train RMSE: 19.62, Validation RMSE = 20.708341403008724\n",
      "Epoch [2000/10000], Train Loss: 386.96, Train RMSE: 19.67, Validation RMSE = 20.70554283423945\n",
      "Epoch [3000/10000], Train Loss: 387.03, Train RMSE: 19.64, Validation RMSE = 20.817089080849165\n",
      "Epoch [4000/10000], Train Loss: 386.92, Train RMSE: 19.71, Validation RMSE = 20.93315406531525\n",
      "Epoch [5000/10000], Train Loss: 386.93, Train RMSE: 19.71, Validation RMSE = 20.939782658761434\n",
      "Epoch [6000/10000], Train Loss: 386.94, Train RMSE: 19.65, Validation RMSE = 20.935593397850734\n",
      "Epoch [7000/10000], Train Loss: 386.92, Train RMSE: 19.64, Validation RMSE = 20.91827879282899\n",
      "Epoch [8000/10000], Train Loss: 386.92, Train RMSE: 19.67, Validation RMSE = 20.94157267515608\n",
      "Epoch [9000/10000], Train Loss: 386.88, Train RMSE: 19.67, Validation RMSE = 20.965410727044752\n",
      "Epoch [10000/10000], Train Loss: 386.88, Train RMSE: 19.67, Validation RMSE = 20.949795858746985\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model = SimpleNet()\n",
    "model.apply(init_weights)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(model,\n",
    "              optimiser,\n",
    "              loss_fn, \n",
    "              10000,\n",
    "              train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7066697-1cae-412e-b328-4349db9b9910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
