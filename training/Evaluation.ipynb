{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83631c7d-b505-4ce2-9b75-b8543b1dfbdf",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59f8e116-16c3-422e-8203-69698b95f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta \n",
    "import numpy as np\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede52fe-a06f-44df-872d-fac6249ee830",
   "metadata": {},
   "source": [
    "## Train model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0370f7ad-acc5-43f0-b246-7d67c5a673e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import config\n",
    "import os\n",
    "import argparse\n",
    "import model_dispatcher\n",
    "\n",
    "clf = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "def score(model, X, y, cv=5, scoring='neg_mean_squared_error'):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def run(df, clf):\n",
    "    # create inputs and targets\n",
    "    X, y = df.drop(columns=['target_va']).values, df.target_va.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "    # score the model\n",
    "    kfold_tabnet(clf, X, y.reshape(-1, 1))\n",
    "\n",
    "def kfold_tabnet(clf, X, y):\n",
    "    rmses = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        rmse = fit_tabnet(clf, X_train, y_train, X_test, y_test)\n",
    "        rmses.append(rmse)\n",
    "    final_rmse, rmse_std = np.round(np.mean(rmses), 2), np.round(np.std(rmses), 2)\n",
    "    print(f\"RMSE: mean={final_rmse}, std={rmse_std}\")\n",
    "    \n",
    "def fit_tabnet(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)],\n",
    "            eval_metric=['rmse'], patience=1000, max_epochs=10000)\n",
    "    preds = clf.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db93c8d3-06ef-4888-90ed-49e79c1a50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 1760 with best_epoch = 760 and best_val_0_rmse = 14.85445\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 1018 with best_epoch = 18 and best_val_0_rmse = 8.86549\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 1000 with best_epoch = 0 and best_val_0_rmse = 9.35031\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 1000 with best_epoch = 0 and best_val_0_rmse = 9.87928\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 1003 with best_epoch = 3 and best_val_0_rmse = 7.26034\n",
      "Best weights from best epoch are automatically used!\n",
      "RMSE: mean=10.04, std=2.56\n"
     ]
    }
   ],
   "source": [
    "run(train_df, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0a880-c725-4c35-a3fc-b6c3ceb2cfb3",
   "metadata": {},
   "source": [
    "## Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d040075-3406-44fb-9d99-501117c60578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_df, clf):\n",
    "    # create inputs and targets\n",
    "    X, y = test_df.drop(columns=['target_va']).values, test_df.target_va.values\n",
    "    # find rmse \n",
    "    preds = clf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a74f1feb-5d59-4d91-8315-68734c8246a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.056606443831818"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_df, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991ffb-22d8-468c-a924-7e69a3b16ab6",
   "metadata": {},
   "source": [
    "## Entire main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63db9673-b794-4436-8017-39292f8e3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta \n",
    "import numpy as np\n",
    "import config\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93475fbf-7c29-4a9c-a917-b7f9090c7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_cutoff(df, cutoff_year, cutoff_visits):\n",
    "    # patients must have this many years of data to be included.\n",
    "    frames = []\n",
    "    id_list = df.eye_id.unique()\n",
    "    for eye in id_list:\n",
    "        pdf = df[df.eye_id == eye]\n",
    "        dates = (pd.to_datetime(pdf.admission_date)).to_list()\n",
    "        if ((dates[-1] - dates[0]).days)/365 >= cutoff_year and len(pdf)>=cutoff_visits: \n",
    "            frames.append(pdf)\n",
    "    return pd.concat(frames)\n",
    "\n",
    "def cut_time(df, cutoff_time):\n",
    "        # shortens a patient's dataframe to x years after initiation.\n",
    "        frames = []\n",
    "        id_list = df.eye_id.unique()\n",
    "        for eye in id_list:\n",
    "            pdf = df[df.eye_id == eye]\n",
    "            pdf.admission_date = pd.to_datetime(pdf.admission_date)\n",
    "            dates = pdf['admission_date'].to_list()\n",
    "            first = pd.to_datetime(dates[0])\n",
    "            cutoff = first + timedelta(days=cutoff_time*365)\n",
    "            pdf = pdf[pdf['admission_date'] <= cutoff]\n",
    "            if len(pdf) > 0: frames.append(pdf)\n",
    "        return pd.concat(frames)\n",
    "    \n",
    "def impute_pdf(df):\n",
    "    fill_NaN = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imputed_df = pd.DataFrame(fill_NaN.fit_transform(df))\n",
    "    imputed_df.columns = df.columns\n",
    "    imputed_df.index = df.index\n",
    "    imputed_df.fillna(0, inplace=True)\n",
    "    return imputed_df\n",
    "\n",
    "def column_names(i):\n",
    "    return [f'va_{i}', f'int_{i}']\n",
    "\n",
    "def column_builder(i):\n",
    "    lst = []\n",
    "    for visits in range(1, i+1):\n",
    "        lst.extend(column_names(visits))\n",
    "    lst.append('mean_vision'), lst.append('std_vision')\n",
    "    lst.append('target_va')\n",
    "    lst.remove('int_1')\n",
    "    return lst\n",
    "\n",
    "def reshape_pdf(pdf, n_visits):\n",
    "    nums, columns = [], column_builder(n_visits)\n",
    "    pdf.fillna(0, inplace=True)\n",
    "    for i in range(n_visits): \n",
    "        nums.append(pdf.visual_acuity.iloc[i])\n",
    "        if i != 0: nums.append((pdf.admission_date.iloc[i] - pdf.admission_date.iloc[i-1]).days)\n",
    "    if n_visits > 6: nums.append(np.mean(pdf.visual_acuity))\n",
    "    else: nums.append(np.mean(pdf.visual_acuity.iloc[:n_visits+1]))\n",
    "    if n_visits > 3: nums.append(np.std(pdf.visual_acuity))\n",
    "    else: nums.append(np.std(pdf.visual_acuity.iloc[:n_visits+1]))\n",
    "    nums.append(pdf.visual_acuity.iloc[-1])\n",
    "    return pd.DataFrame(data=[nums], columns=columns)\n",
    "\n",
    "def encode_gender(g):\n",
    "    return 0 if g == \"Male\" else 1\n",
    "\n",
    "def reshape_df(df, n_visits):\n",
    "    eyes = df.eye_id.unique()\n",
    "    frames = []\n",
    "    for eye in eyes:\n",
    "        pdf = df[df.eye_id == eye]\n",
    "        try: frames.append(reshape_pdf(pdf, n_visits))\n",
    "        except: pass\n",
    "    return pd.concat(frames)\n",
    "\n",
    "def save_df_patients(n_years, n_visits=4):\n",
    "    df = pd.read_csv(\"~/Documents/github/paper/input/raw_test_data_cleaned.csv\")\n",
    "    df.drop(columns=['actual_drug_today', 'next_interval_in_weeks', 'InjNext',\n",
    "                     'laterality'], inplace=True)\n",
    "    df[\"irf\"] = 0\n",
    "    df[\"srf\"] = 0\n",
    "    df = patient_cutoff(df, n_years, 4)\n",
    "    df = cut_time(df, n_years)\n",
    "    df = reshape_df(df, n_visits)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c8e438-5b9e-4ad3-b67c-af8614ed6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(n_years):\n",
    "    test_df = save_df_patients(n_years)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_df = pd.read_csv(config.TRAINING_FILE[n_years-1])\n",
    "    features = ['va_1', 'va_2', 'int_2', 'va_3', 'int_3', 'va_4', 'int_4', \n",
    "                'mean_vision', 'std_vision', 'target_va']\n",
    "    train_df = train_df[features]\n",
    "    return train_df, test_df\n",
    "\n",
    "tabnet_params = {\"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"verbose\":0,\n",
    "                 \"optimizer_params\":dict(lr=2e-2),\n",
    "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'entmax' # \"sparsemax\"\n",
    "                }\n",
    "\n",
    "def score(model, X, y, cv=5, scoring='neg_mean_squared_error'):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def run(df, clf, rf=False):\n",
    "    # create inputs and targets\n",
    "    X, y = df.drop(columns=['target_va']).values, df.target_va.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "    # score the model\n",
    "    if rf: rf.fit(X_train, y_train)\n",
    "    else: kfold_tabnet(clf, X, y.reshape(-1, 1))\n",
    "\n",
    "def kfold_tabnet(clf, X, y):\n",
    "    rmses = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        rmse = fit_tabnet(clf, X_train, y_train, X_test, y_test)\n",
    "        rmses.append(rmse)\n",
    "    final_rmse, rmse_std = np.round(np.mean(rmses), 2), np.round(np.std(rmses), 2)\n",
    "    print(f\"Train-set RMSE: mean={final_rmse}, std={rmse_std}\")\n",
    "    \n",
    "def fit_tabnet(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_test, y_test)],\n",
    "            eval_metric=['rmse'], patience=1000, max_epochs=10000)\n",
    "    preds = clf.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return rmse\n",
    "\n",
    "def evaluate(test_df, clf):\n",
    "    # create inputs and targets\n",
    "    X, y = test_df.drop(columns=['target_va']).values, test_df.target_va.values\n",
    "    # find rmse \n",
    "    preds = clf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    print(f\"The RMSE on the test-set was {rmse} logMAR letters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf6ce3f1-aba5-458f-8214-45af52cbc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_years, rf=False):\n",
    "    train_df, test_df = get_train_test(n_years)\n",
    "    if rf:\n",
    "        clf = ensemble.RandomForestRegressor()\n",
    "    else:\n",
    "        clf = TabNetRegressor(**tabnet_params)\n",
    "    run(train_df, clf, rf)\n",
    "    evaluate(test_df, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a6e1d-43c2-4a85-901a-8594bf564454",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(3, rf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45878bce-a672-473c-944d-33e2976fea20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
